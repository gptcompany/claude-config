---
phase: 14.6-hooks-integration-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [~/.claude/scripts/hooks/e2e/session-lifecycle.test.js, ~/.claude/scripts/hooks/e2e/gsd-workflow.test.js, ~/.claude/scripts/hooks/e2e/multi-agent.test.js, ~/.claude/scripts/hooks/e2e/orchestrator-hooks.test.js]
autonomous: true
---

<objective>
E2E integration tests validating complete hook chains work together in real scenarios.

Purpose: Prove hooks work end-to-end, not just in isolation. Tests simulate real Claude Code usage patterns.
Output: 4 test files with ~90 tests covering session lifecycle, GSD workflow, multi-agent coordination, and ValidationOrchestrator integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14.5-hooks-shared-port/14.5-08-SUMMARY.md

# Existing test infrastructure
@~/.claude/scripts/hooks/integration.test.js

# Hook directories
# ~/.claude/scripts/hooks/{safety,intelligence,quality,productivity,metrics,coordination,ux,control,debug}/
</context>

<tasks>

<task type="auto">
  <name>Task 1: Session Lifecycle E2E Tests</name>
  <files>~/.claude/scripts/hooks/e2e/session-lifecycle.test.js</files>
  <action>
Create comprehensive session lifecycle E2E tests (~25 tests):

**Test chains:**
1. `session-start -> tips-injector -> lesson-injector -> intelligence hooks` (5 tests)
   - Verify session state persists between hooks
   - Verify tips/lessons injected into context
   - Verify start time tracked for metrics

2. `tool-use -> safety-check -> file-coordination -> task-coordination` (5 tests)
   - Verify dangerous commands blocked before file access
   - Verify file claims work correctly
   - Verify task claims coordinate properly

3. `edit -> auto-format -> plan-validator -> architecture-validator` (5 tests)
   - Verify edits trigger format check
   - Verify plan structure validated
   - Verify architecture consistency checked

4. `session-end -> session-analyzer -> session-insights -> metrics-export` (5 tests)
   - Verify session analyzed correctly
   - Verify insights generated
   - Verify metrics exported to QuestDB

5. `full-session-simulation` (5 tests)
   - Start session with empty state
   - Simulate 10 tool uses
   - End session and verify all hooks fired
   - Verify metrics match expectations
   - Verify session state consistent

Use Node.js test runner. Create temp directories for isolation. Mock QuestDB if unavailable.
  </action>
  <verify>node --test ~/.claude/scripts/hooks/e2e/session-lifecycle.test.js passes all tests</verify>
  <done>25 session lifecycle E2E tests pass</done>
</task>

<task type="auto">
  <name>Task 2: GSD Workflow E2E Tests</name>
  <files>~/.claude/scripts/hooks/e2e/gsd-workflow.test.js</files>
  <action>
Create GSD workflow E2E tests (~25 tests):

**Test scenarios:**
1. `/gsd:plan-phase` workflow (5 tests)
   - Hook chain: task-checkpoint -> plan-validator -> tdd-guard
   - Verify plan validation runs on plan file write
   - Verify task checkpoint saves state

2. `/gsd:execute-plan` workflow (5 tests)
   - Hook chain: file-coordination -> safety hooks -> quality hooks -> metrics
   - Verify file claims during execution
   - Verify quality checks run
   - Verify DORA metrics tracked

3. `/gsd:sync-github` workflow (3 tests)
   - Verify claudeflow-sync hook fires
   - Verify GitHub integration doesn't break on missing config

4. `plan-validator with real .planning/` (4 tests)
   - Use actual .planning/ directory structure
   - Validate PLAN.md format detection
   - Verify dependency graph parsing

5. `tdd-guard integration` (4 tests)
   - Detect test file writes
   - Verify TDD cycle tracking
   - Check RED->GREEN->REFACTOR state machine

6. `dora-tracker integration` (4 tests)
   - Track commit frequency
   - Track deployment events
   - Verify metrics export

Use existing .planning/ as test fixture where appropriate. Isolate destructive tests.
  </action>
  <verify>node --test ~/.claude/scripts/hooks/e2e/gsd-workflow.test.js passes all tests</verify>
  <done>25 GSD workflow E2E tests pass</done>
</task>

<task type="auto">
  <name>Task 3: Multi-Agent Coordination E2E Tests</name>
  <files>~/.claude/scripts/hooks/e2e/multi-agent.test.js</files>
  <action>
Create multi-agent coordination E2E tests (~20 tests):

**Test scenarios:**
1. `file-coordination claim/release` (5 tests)
   - Agent A claims file
   - Agent B attempts claim -> blocked
   - Agent A releases
   - Agent B successfully claims
   - Stale claim cleanup works

2. `task-coordination claim/release` (5 tests)
   - Same pattern for task claims
   - Verify task state persistence
   - Verify handoff works

3. `hive-manager coordination` (5 tests)
   - Initialize hive
   - Add workers
   - Coordinate task distribution
   - Verify consensus mechanism
   - Shutdown cleanly

4. `concurrent hook execution` (5 tests)
   - Simulate 3 agents running hooks simultaneously
   - Verify no race conditions in metrics
   - Verify file locks work
   - Verify QuestDB writes don't corrupt
   - Verify claim conflicts resolved correctly

Use child_process to spawn parallel hook executions. Test actual concurrency.
  </action>
  <verify>node --test ~/.claude/scripts/hooks/e2e/multi-agent.test.js passes all tests</verify>
  <done>20 multi-agent E2E tests pass</done>
</task>

<task type="auto">
  <name>Task 4: ValidationOrchestrator + Hooks E2E Tests</name>
  <files>~/.claude/scripts/hooks/e2e/orchestrator-hooks.test.js</files>
  <action>
Create ValidationOrchestrator integration tests (~20 tests):

**Test scenarios:**
1. `hooks trigger orchestrator` (5 tests)
   - ralph-loop hook triggers validation
   - Verify tier filtering works
   - Verify backpressure mechanism
   - Verify result caching
   - Verify timeout handling

2. `orchestrator reports to hooks` (5 tests)
   - Validation results exported via metrics hooks
   - QuestDB receives validation scores
   - Grafana reporter generates output
   - Terminal reporter shows results
   - Confidence scores tracked

3. `quality-score integration` (5 tests)
   - quality-score hook calls orchestrator
   - Verify 14-dimension aggregation
   - Verify weighted scoring
   - Verify threshold detection
   - Verify pass/fail determination

4. `pr-readiness with orchestrator` (5 tests)
   - PR readiness uses validation results
   - Verify blocking on Tier 1 failures
   - Verify warnings on Tier 2 failures
   - Verify report generation
   - Verify GitHub status update capability

Note: These tests require the Python orchestrator. Use subprocess to call it, or mock if unavailable.
Skip tests gracefully if orchestrator not installed.
  </action>
  <verify>node --test ~/.claude/scripts/hooks/e2e/orchestrator-hooks.test.js passes (or skips gracefully)</verify>
  <done>20 orchestrator E2E tests pass or skip cleanly</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] node --test ~/.claude/scripts/hooks/e2e/session-lifecycle.test.js passes
- [ ] node --test ~/.claude/scripts/hooks/e2e/gsd-workflow.test.js passes
- [ ] node --test ~/.claude/scripts/hooks/e2e/multi-agent.test.js passes
- [ ] node --test ~/.claude/scripts/hooks/e2e/orchestrator-hooks.test.js passes (or skips)
- [ ] All 4 test files created in e2e/ directory
- [ ] Total ~90 E2E tests added
</verification>

<success_criteria>
- All tasks completed
- ~90 E2E tests written and passing
- No regressions in existing tests
- Tests use Node.js built-in test runner
- Tests isolated with proper cleanup
</success_criteria>

<output>
After completion, create `.planning/phases/14.6-hooks-integration-validation/14.6-01-SUMMARY.md`
</output>
