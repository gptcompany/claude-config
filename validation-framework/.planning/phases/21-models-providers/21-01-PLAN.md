---
phase: 21-models-providers
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - /home/sam/moltbot-infra/clawdbot-config/openclaw.json
  - /home/sam/moltbot-infra/docker-compose.yml
autonomous: false
user_setup:
  - service: openrouter
    why: "Kimi K2.5 cross-review via OpenRouter"
    env_vars:
      - name: OPENROUTER_API_KEY
        source: "Already in SOPS /media/sam/1TB/.env.enc — verify it's injected into gateway container"
    account_setup: []
    dashboard_config: []
    local_dev: []
---

<objective>
Configure OpenClaw multi-model providers: add Kimi K2.5 via OpenRouter, Gemini, and OpenAI as fallbacks alongside existing Anthropic primary. Enable LLM Task plugin for cross-model review. Update docker-compose env injection.

Purpose: Enable multi-model setup for Phase 25 (Gemini cross-review) and Phase 27 (autonomous loop) — foundational provider config.
Output: Updated openclaw.json with 4 providers, model aliases, failover chain, LLM Task plugin. Docker-compose with env vars. Verified via `openclaw doctor`.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/21-models-providers/21-RESEARCH.md

# Current openclaw.json is on muletto:
# /home/sam/moltbot-infra/clawdbot-config/openclaw.json
# Access via: ssh 192.168.1.100 'cat /home/sam/moltbot-infra/clawdbot-config/openclaw.json'

# Current state (from research):
# - Only anthropic provider configured (3 auth profiles: anth, manual, default)
# - No fallback chain
# - No model aliases
# - plugins: only "matrix" enabled
# - OPENROUTER_API_KEY already in SOPS
# - GEMINI_API_KEY already in SOPS
# - OPENAI_API_KEY already in SOPS
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update openclaw.json with multi-model config</name>
  <files>/home/sam/moltbot-infra/clawdbot-config/openclaw.json (on muletto via SSH)</files>
  <action>
SSH into muletto (192.168.1.100) and update openclaw.json:

1. **agents.defaults.model**: Add fallback chain:
   ```json
   "model": {
     "primary": "anthropic/claude-opus-4-5",
     "fallbacks": ["openrouter/moonshotai/kimi-k2.5", "google/gemini-2.5-pro", "openai/gpt-5.2"]
   }
   ```

2. **agents.defaults.models**: Add model aliases:
   ```json
   "models": {
     "anthropic/claude-opus-4-5": { "alias": "opus" },
     "openrouter/moonshotai/kimi-k2.5": { "alias": "kimi" },
     "google/gemini-2.5-pro": { "alias": "gemini" },
     "openai/gpt-5.2": { "alias": "gpt" }
   }
   ```

3. **auth.profiles**: Add new provider profiles (keep existing anthropic ones):
   ```json
   "openrouter:default": { "provider": "openrouter", "mode": "token" },
   "google:default": { "provider": "google", "mode": "token" },
   "openai:default": { "provider": "openai", "mode": "token" }
   ```

4. **plugins**: Add llm-task alongside matrix:
   ```json
   "plugins": {
     "allow": ["matrix", "llm-task"],
     "load": { "paths": ["/app/extensions/matrix"] },
     "entries": {
       "matrix": { "enabled": true },
       "llm-task": { "enabled": true }
     }
   }
   ```

5. **tools.allow**: Add "llm_task" to agent tool allowlist (if tools.allow exists, append; if tools.deny only, ensure llm_task not denied).

6. **auth.cooldowns**: Add failover cooldown config:
   ```json
   "cooldowns": {
     "billingBackoffHours": 5,
     "billingMaxHours": 24,
     "failureWindowHours": 24
   }
   ```

**IMPORTANT:**
- Do NOT remove existing config fields — merge into existing structure
- Use `python3 -c` or `jq` to edit JSON safely, avoid manual edits
- Backup before editing: `cp openclaw.json openclaw.json.bak-$(date +%Y%m%d-%H%M%S)`
- Validate JSON after: `python3 -m json.tool openclaw.json`
  </action>
  <verify>
    - ssh 192.168.1.100 'python3 -m json.tool /home/sam/moltbot-infra/clawdbot-config/openclaw.json > /dev/null' succeeds (valid JSON)
    - ssh 192.168.1.100 'cat /home/sam/moltbot-infra/clawdbot-config/openclaw.json' | python3 -c "import sys,json; d=json.load(sys.stdin); assert 'fallbacks' in d['agents']['defaults']['model']"
    - ssh 192.168.1.100 'cat /home/sam/moltbot-infra/clawdbot-config/openclaw.json' | python3 -c "import sys,json; d=json.load(sys.stdin); assert 'llm-task' in d['plugins']['allow']"
  </verify>
  <done>openclaw.json has 4 providers, fallback chain, model aliases, LLM Task plugin, cooldown config</done>
</task>

<task type="auto">
  <name>Task 2: Update docker-compose env vars for new providers</name>
  <files>/home/sam/moltbot-infra/docker-compose.yml (on muletto via SSH)</files>
  <action>
SSH into muletto and update the openclaw-gateway service in docker-compose.yml:

1. Find the `openclaw-gateway` service environment section
2. Add env vars (if not already present):
   ```yaml
   - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
   - GEMINI_API_KEY=${GEMINI_API_KEY}
   - OPENAI_API_KEY=${OPENAI_API_KEY}
   ```
   Keep existing `ANTHROPIC_API_KEY` if present.

3. Verify the docker-compose has a mechanism to load from SOPS (check if there's an `.env` file or `env_file:` directive, or if the start script decrypts SOPS first).

**NOTE:** If docker-compose uses `.env` file pattern, verify the keys exist there (or are loaded from SOPS at startup). If using `start-secure.sh` pattern, confirm it decrypts the needed keys.

**Backup first:** `cp docker-compose.yml docker-compose.yml.bak-$(date +%Y%m%d-%H%M%S)`
  </action>
  <verify>
    - ssh 192.168.1.100 'grep OPENROUTER_API_KEY /home/sam/moltbot-infra/docker-compose.yml' returns match
    - ssh 192.168.1.100 'grep GEMINI_API_KEY /home/sam/moltbot-infra/docker-compose.yml' returns match
    - ssh 192.168.1.100 'docker compose -f /home/sam/moltbot-infra/docker-compose.yml config --quiet' succeeds (valid compose)
  </verify>
  <done>Docker-compose injects OPENROUTER_API_KEY, GEMINI_API_KEY, OPENAI_API_KEY into gateway container</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Multi-model provider config in openclaw.json + docker-compose env vars. 4 providers (Anthropic primary, OpenRouter/Kimi K2.5, Gemini, OpenAI), model aliases (/opus, /kimi, /gemini, /gpt), LLM Task plugin, failover chain with cooldowns.</what-built>
  <how-to-verify>
    1. SSH into muletto: `ssh 192.168.1.100`
    2. Restart gateway: `cd /home/sam/moltbot-infra && docker compose up -d openclaw-gateway`
    3. Run doctor: `docker exec openclaw-gateway node /app/dist/entry.js doctor`
    4. Verify providers listed: should show anthropic, openrouter, google, openai
    5. Verify LLM Task plugin: `docker exec openclaw-gateway node /app/dist/entry.js skills list` should show llm_task
    6. Test model alias: in Bambam Matrix, send `/kimi hello` to verify OpenRouter responds
    7. Check logs for errors: `docker logs openclaw-gateway --tail 20`
  </how-to-verify>
  <resume-signal>Type "approved" if doctor passes and providers are recognized, or describe issues</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] openclaw.json is valid JSON with 4 providers configured
- [ ] Fallback chain: opus → kimi → gemini → gpt
- [ ] Model aliases defined: opus, kimi, gemini, gpt
- [ ] LLM Task plugin enabled
- [ ] Docker-compose injects all 4 API key env vars
- [ ] Gateway restarts without errors
- [ ] `openclaw doctor` passes
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Gateway running with multi-model config
- LLM Task plugin available for cross-model review (Phase 25)
- Failover chain configured (even if bug #4260 not yet fixed)
  </success_criteria>

<output>
After completion, create `.planning/phases/21-models-providers/21-01-SUMMARY.md`
</output>
