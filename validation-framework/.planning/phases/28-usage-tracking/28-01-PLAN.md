---
phase: 28-usage-tracking
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - /home/sam/moltbot-infra/clawdbot-config/openclaw.json
  - /media/sam/1TB/moltbot-iac/workstation/otel-collector.yaml
  - /media/sam/1TB/moltbot-iac/workstation/docker-compose.otel.yml
  - /media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh
  - /etc/systemd/system/budget-enforcer.timer
  - /etc/systemd/system/budget-enforcer.service
autonomous: true
user_setup: []
---

<objective>
Enable OpenClaw token/cost tracking via OTEL pipeline to Prometheus, and deploy a budget enforcer that hard-stops agents when daily spend exceeds threshold.

Purpose: Visibility into per-provider/per-model cost, and safety cap to prevent runaway spend in autonomous loop.
Output: OTEL metrics flowing into Prometheus, budget enforcer cron active, cost config per provider.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-usage-tracking/28-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enable OTEL diagnostics + cost config in openclaw.json</name>
  <files>/home/sam/moltbot-infra/clawdbot-config/openclaw.json</files>
  <action>
  SSH to muletto (192.168.1.100) and edit the openclaw.json config to:

  1. Add `diagnostics-otel` to `plugins.allow` array
  2. Add `diagnostics-otel` entry in `plugins.entries` with `enabled: true`
  3. Add `diagnostics` section with OTEL config:
     - endpoint: `http://192.168.1.111:4318` (Workstation OTEL Collector)
     - protocol: `http/protobuf`
     - serviceName: `openclaw-gateway`
     - metrics: true, traces: false, logs: false
     - flushIntervalMs: 30000
  4. Add cost entries for each provider's models in `models.providers.*.models[].cost`:
     - anthropic claude-sonnet-4: input=3.0, output=15.0, cacheRead=0.30, cacheWrite=3.75
     - openrouter gemini-2.5-flash: input=0.15, output=0.60, cacheRead=0.0375, cacheWrite=0.15
     - google gemini (if present): input=0 (OAuth, free tier)
  5. Restart gateway container: `docker restart openclaw-gateway`

  Read the current config first to understand existing structure. DO NOT overwrite unrelated sections.
  </action>
  <verify>
  SSH to muletto and run:
  - `docker exec openclaw-gateway node /app/dist/entry.js config get diagnostics` — should show otel enabled
  - `docker logs openclaw-gateway --tail 20 2>&1 | grep -i otel` — should show OTEL initialization
  </verify>
  <done>OTEL diagnostics enabled in openclaw.json, cost config set per provider, gateway restarted successfully</done>
</task>

<task type="auto">
  <name>Task 2: Deploy OTEL Collector on Workstation + verify metrics in Prometheus</name>
  <files>/media/sam/1TB/moltbot-iac/workstation/otel-collector.yaml, /media/sam/1TB/moltbot-iac/workstation/docker-compose.otel.yml</files>
  <action>
  On the Workstation (localhost):

  1. Check if Prometheus is already configured for remote write (check existing docker-compose/config).
     Check if Grafana Alloy is already running — if yes, configure it as OTEL receiver instead of deploying a separate collector.

  2. If no existing OTEL-capable receiver:
     a. Create `otel-collector.yaml` with:
        - OTLP HTTP receiver on 0.0.0.0:4318
        - Batch processor (30s timeout)
        - Prometheus remote write exporter to existing Prometheus endpoint
     b. Create `docker-compose.otel.yml` (or add to existing compose) with:
        - `otel/opentelemetry-collector-contrib:latest` image
        - Port 4318 exposed
        - Volume mount for config
        - Network access to Prometheus
     c. Start the collector: `docker compose -f docker-compose.otel.yml up -d`

  3. Verify Prometheus is receiving metrics:
     - Trigger a short OpenClaw session (any agent, simple query)
     - Wait 60s for flush
     - Query Prometheus: `curl -s 'http://localhost:9090/api/v1/query?query=openclaw_tokens_total' | jq '.data.result | length'`
     - Should return > 0

  IMPORTANT: Check existing Grafana/Prometheus stack first (likely in /media/sam/1TB/ somewhere). Don't duplicate infrastructure.
  If Prometheus doesn't support remote_write, use the `prometheus` exporter (scrape endpoint) instead of `prometheusremotewrite`.
  </action>
  <verify>
  - `docker ps | grep otel` — collector running
  - `curl -s http://localhost:4318/` — OTEL endpoint responsive
  - `curl -s 'http://localhost:9090/api/v1/query?query=up{job=~".*otel.*"}' | jq .` — or check for `openclaw_*` metrics
  </verify>
  <done>OTEL Collector running, receiving metrics from OpenClaw gateway, forwarding to Prometheus. At least one `openclaw_*` metric visible in Prometheus.</done>
</task>

<task type="auto">
  <name>Task 3: Deploy budget enforcer cron with Matrix escalation</name>
  <files>/media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh, /etc/systemd/system/budget-enforcer.timer, /etc/systemd/system/budget-enforcer.service</files>
  <action>
  Create a budget enforcer that runs every 5 minutes:

  1. Create `/media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh`:
     - Query Prometheus: `sum(increase(openclaw_cost_usd_total[24h]))`
     - Compare against MAX_DAILY_USD=5.00 (configurable via env var)
     - If over budget:
       a. Send Matrix message to bambam room via Synapse API (reuse pattern from autonomous-loop escalation)
       b. Create a flag file `/tmp/openclaw-budget-exceeded` that hooks can check
     - If under budget and flag exists, remove flag (auto-recover next day)
     - Log each check to syslog or `/var/log/budget-enforcer.log`

  2. Create systemd timer + service:
     - `budget-enforcer.service`: Type=oneshot, ExecStart=/media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh
     - `budget-enforcer.timer`: OnCalendar=*:0/5 (every 5 min)
     - Enable and start timer

  3. Also create a pre-session hook check:
     - If `/tmp/openclaw-budget-exceeded` exists, the OpenClaw `validation-gate` hook (Phase 26) should check this flag and block new sessions.
     - Document how to add this check to existing hook (in SUMMARY, don't modify hook code here — that's Phase 26 territory, already deployed).

  Use `bc` for float comparison. Ensure the script works if Prometheus returns no data (treat as $0).
  Matrix API: POST to `https://matrix.lan/_matrix/client/v3/rooms/!GQeiGgJenxtCKbaxDL:matrix.lan/send/m.room.message` with bot token.
  </action>
  <verify>
  - `bash /media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh` — runs without error, logs output
  - `systemctl status budget-enforcer.timer` — active
  - `journalctl -u budget-enforcer.service --no-pager -n 5` — shows recent check
  </verify>
  <done>Budget enforcer running every 5 min, queries Prometheus for daily spend, escalates to Matrix and creates flag file on overspend. Systemd timer active.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `openclaw_tokens_total` metric visible in Prometheus
- [ ] `openclaw_cost_usd_total` metric visible in Prometheus (may be 0 if no paid API calls yet)
- [ ] OTEL Collector container healthy
- [ ] Budget enforcer timer active and running
- [ ] Budget enforcer correctly handles "no data" case (Prometheus empty)
- [ ] Flag file mechanism works (create/remove)
</verification>

<success_criteria>

- OTEL pipeline: OpenClaw → Collector → Prometheus working end-to-end
- Cost config set for all configured providers
- Budget enforcer cron active with Matrix escalation
- No errors in OpenClaw gateway logs related to OTEL
- All verification checks pass
</success_criteria>

<output>
After completion, create `.planning/phases/28-usage-tracking/28-01-SUMMARY.md`
</output>
