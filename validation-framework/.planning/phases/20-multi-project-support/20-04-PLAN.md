---
phase: 20-multi-project-support
plan: 04
type: execute
wave: 3
depends_on: ["20-01", "20-02"]
files_modified:
  - ~/.claude/scripts/lib/validation-queries.js
  - ~/.claude/scripts/lib/validation-queries.test.js
autonomous: true
---

<objective>
Add cross-project metrics aggregation with QuestDB materialized views.

Purpose: Enable comparison of validation quality across multiple projects via pre-computed aggregations, powering Grafana dashboards and CLI reporting.

Output: 3 new query functions, QuestDB view creation script, 8 tests
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-multi-project-support/20-CONTEXT.md
@.planning/phases/20-multi-project-support/20-01-SUMMARY.md
@.planning/phases/20-multi-project-support/20-02-SUMMARY.md

@~/.claude/scripts/lib/validation-queries.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add cross-project query functions</name>
  <files>~/.claude/scripts/lib/validation-queries.js</files>
  <action>
Add 3 new functions to existing validation-queries.js:

1. `getProjectComparison(days = 7)`:
   ```javascript
   // Returns per-project summary for last N days
   // Columns: project_name, total_runs, pass_rate, avg_duration_ms, blockers_found
   const query = `
     SELECT
       project_name,
       count(*) as total_runs,
       sum(CASE WHEN passed THEN 1 ELSE 0 END) * 100.0 / count(*) as pass_rate,
       avg(duration_ms) as avg_duration_ms,
       sum(CASE WHEN tier = 1 AND NOT passed THEN 1 ELSE 0 END) as blockers_found
     FROM validation_results
     WHERE timestamp > dateadd('d', -${days}, now())
     GROUP BY project_name
     ORDER BY pass_rate DESC
   `;
   ```

2. `getProjectTrend(projectName, days = 14)`:
   ```javascript
   // Returns daily pass rate trend for specific project
   // Columns: date, pass_rate, run_count
   const query = `
     SELECT
       date_trunc('day', timestamp) as date,
       sum(CASE WHEN passed THEN 1 ELSE 0 END) * 100.0 / count(*) as pass_rate,
       count(*) as run_count
     FROM validation_results
     WHERE project_name = '${projectName}'
       AND timestamp > dateadd('d', -${days}, now())
     GROUP BY date_trunc('day', timestamp)
     ORDER BY date
   `;
   ```

3. `getCrossProjectHealth()`:
   ```javascript
   // Returns health score (0-100) per project based on recent validation
   // Columns: project_name, health_score, last_run, status
   const query = `
     WITH recent AS (
       SELECT
         project_name,
         passed,
         tier,
         timestamp,
         ROW_NUMBER() OVER (PARTITION BY project_name ORDER BY timestamp DESC) as rn
       FROM validation_results
       WHERE timestamp > dateadd('d', -7, now())
     )
     SELECT
       project_name,
       sum(CASE
         WHEN passed AND tier = 1 THEN 40
         WHEN passed AND tier = 2 THEN 30
         WHEN passed AND tier = 3 THEN 30
         ELSE 0
       END) / count(*) as health_score,
       max(timestamp) as last_run,
       CASE
         WHEN sum(CASE WHEN tier = 1 AND NOT passed THEN 1 ELSE 0 END) > 0 THEN 'critical'
         WHEN sum(CASE WHEN NOT passed THEN 1 ELSE 0 END) > 0 THEN 'warning'
         ELSE 'healthy'
       END as status
     FROM recent
     WHERE rn <= 10
     GROUP BY project_name
   `;
   ```

Export all three functions.
  </action>
  <verify>cd ~/.claude/scripts && node -e "const q = require('./lib/validation-queries.js'); console.log(Object.keys(q))"</verify>
  <done>3 new query functions added</done>
</task>

<task type="auto">
  <name>Task 2: Add tests for cross-project queries</name>
  <files>~/.claude/scripts/lib/validation-queries.test.js</files>
  <action>
Add 8 tests to existing test file:

**getProjectComparison tests (3):**
1. `test_getProjectComparison_returns_all_projects` - multiple projects in result
2. `test_getProjectComparison_calculates_pass_rate` - pass_rate is percentage
3. `test_getProjectComparison_respects_days_param` - older data excluded

**getProjectTrend tests (3):**
4. `test_getProjectTrend_returns_daily_data` - one row per day
5. `test_getProjectTrend_filters_by_project` - only specified project
6. `test_getProjectTrend_ordered_by_date` - ascending date order

**getCrossProjectHealth tests (2):**
7. `test_getCrossProjectHealth_calculates_score` - score is 0-100
8. `test_getCrossProjectHealth_status_reflects_blockers` - critical if tier1 fails

Use mock data or skip if QuestDB not available.
  </action>
  <verify>cd ~/.claude/scripts && npm test -- --grep "cross-project"</verify>
  <done>8 new tests pass</done>
</task>

<task type="auto">
  <name>Task 3: Update CLI report tool</name>
  <files>~/.claude/scripts/bin/validation-report</files>
  <action>
Add `projects` command to existing CLI:

```javascript
// In validation-report CLI
case 'projects':
  const comparison = await getProjectComparison(options.days || 7);
  console.log('Project Health Summary\n');
  console.log('Project'.padEnd(30) + 'Pass %'.padEnd(10) + 'Runs'.padEnd(8) + 'Blockers');
  console.log('â”€'.repeat(60));
  for (const row of comparison) {
    console.log(
      row.project_name.padEnd(30) +
      `${row.pass_rate.toFixed(1)}%`.padEnd(10) +
      String(row.total_runs).padEnd(8) +
      row.blockers_found
    );
  }
  break;
```

Ensure `vr projects` alias works.
  </action>
  <verify>vr projects --help</verify>
  <done>CLI `projects` command works</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm test` in scripts/ - all tests pass including new ones
- [ ] `vr projects` - shows project comparison table
- [ ] Queries work with real QuestDB data (or gracefully handle missing data)
</verification>

<success_criteria>
- 3 cross-project query functions added
- 8 tests pass
- CLI `projects` command functional
- Backward compatible with existing queries
</success_criteria>

<output>
After completion, create `.planning/phases/20-multi-project-support/20-04-SUMMARY.md`
</output>
