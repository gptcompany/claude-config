---
phase: 06-hybrid-uat-validators
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - ~/.claude/templates/validation/hybrid/confidence.py.j2
  - ~/.claude/templates/validation/hybrid/dashboard.py.j2
  - ~/.claude/templates/validation/hybrid/verify_work.py.j2
  - ~/.claude/templates/validation/hybrid/README.md
autonomous: true
---

<objective>
Create hybrid verify-work templates with confidence scoring and multi-mode dashboard.

Purpose: Enable four-round UAT workflow (Auto → Human-All → Fix → Edge+Regression) with intelligent confidence filtering.
Output: Jinja2 templates for confidence scoring module, TUI dashboard, and verify-work orchestrator.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-hybrid-uat-validators/06-CONTEXT.md
@.planning/phases/06-hybrid-uat-validators/06-RESEARCH.md
@~/.claude/templates/validation/config.schema.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create confidence scoring module template</name>
  <files>~/.claude/templates/validation/hybrid/confidence.py.j2</files>
  <action>
Create a Jinja2 template for confidence scoring that:
1. Calculates confidence (0-100) based on:
   - Flaky rate (reduce score if > 10%)
   - Coverage percentage (reduce if < 80%)
   - Known issues count (reduce 5 points each)
   - Historical pass rate
2. Classifies as HIGH (≥80), MEDIUM (50-79), LOW (<50)
3. Supports type classification (unit, integration, e2e, visual, a11y, security, perf)
4. Returns structured result with score, level, factors

Use dataclass for result structure. Include Jinja2 variables for:
- {{ project_name }}
- {{ confidence_thresholds | default({'high': 80, 'medium': 50}) }}

Follow pattern from research: metrics-based calculation that adapts to test history.
  </action>
  <verify>python3 -c "import jinja2; jinja2.Template(open('~/.claude/templates/validation/hybrid/confidence.py.j2').read())"</verify>
  <done>Template renders valid Python with confidence scoring logic</done>
</task>

<task type="auto">
  <name>Task 2: Create TUI dashboard template</name>
  <files>~/.claude/templates/validation/hybrid/dashboard.py.j2</files>
  <action>
Create a Jinja2 template for Textual-based TUI dashboard with three modes:
1. **Live Monitor**: Real-time test execution view
   - Progress bar for overall completion
   - Live log of running tests
   - Confidence scores updating in real-time
2. **Review Station**: Interactive review interface
   - Table of all results with confidence colors (HIGH=green, MEDIUM=yellow, LOW=red)
   - Keyboard navigation (j/k up/down, Enter to drill in)
   - Mark pass/fail with notes
   - Filter by confidence level and type
3. **Report Viewer**: Summary after completion
   - Overall pass/fail count
   - Grouped by confidence level
   - Export to Allure-compatible JSON

Use Textual widgets: DataTable, ProgressBar, Log, Static.
Include Jinja2 variables for:
- {{ project_name }}
- {{ dashboard_title | default('Validation Dashboard') }}
- {{ refresh_rate | default(1.0) }}

IMPORTANT: Keep it simple - no over-engineering. Single file, core functionality only.
  </action>
  <verify>python3 -c "import jinja2; jinja2.Template(open('~/.claude/templates/validation/hybrid/dashboard.py.j2').read())"</verify>
  <done>Template renders valid Python with Textual TUI dashboard</done>
</task>

<task type="auto">
  <name>Task 3: Create verify-work orchestrator template</name>
  <files>~/.claude/templates/validation/hybrid/verify_work.py.j2</files>
  <action>
Create a Jinja2 template for the four-round UAT orchestrator:
1. **Round 1 (Auto-Check)**: Run all automated validators, collect results with confidence
2. **Round 2 (Human-All)**: Present ALL results to human via dashboard, guided by confidence
3. **Round 3 (Fix + Retest)**: Re-run failed tests after fixes
4. **Round 4 (Edge + Regression)**: Run edge cases and full regression

The orchestrator should:
- Use subprocess to run pytest, Playwright, and other validators
- Collect results into unified format
- Calculate confidence per result
- Launch dashboard for human review
- Track fix attempts and re-test status
- Generate final report

Include Jinja2 variables for:
- {{ project_name }}
- {{ validators | default(['pytest', 'playwright']) }}
- {{ edge_case_markers | default(['edge', 'regression']) }}

Follow "prove me wrong" philosophy: even HIGH confidence items get human review.
  </action>
  <verify>python3 -c "import jinja2; jinja2.Template(open('~/.claude/templates/validation/hybrid/verify_work.py.j2').read())"</verify>
  <done>Template renders valid Python with four-round UAT orchestrator</done>
</task>

<task type="auto">
  <name>Task 4: Create hybrid module README</name>
  <files>~/.claude/templates/validation/hybrid/README.md</files>
  <action>
Create README.md documenting the hybrid UAT workflow:
1. Overview of four-round approach
2. Confidence scoring algorithm explanation
3. Dashboard modes and usage
4. Integration with other validators (a11y, security, perf)
5. CLI usage examples
6. Configuration options via config.json

Include example config.json snippet for hybrid settings.
Keep it concise - no enterprise fluff.
  </action>
  <verify>test -f ~/.claude/templates/validation/hybrid/README.md</verify>
  <done>README exists with usage documentation</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] All 4 files created in ~/.claude/templates/validation/hybrid/
- [ ] All .j2 templates are valid Jinja2 (render without error)
- [ ] Python code in templates is syntactically valid
- [ ] README documents the workflow clearly
</verification>

<success_criteria>

- All tasks completed
- Templates render valid Python code
- Hybrid UAT workflow is fully documented
- No errors or warnings introduced
</success_criteria>

<output>
After completion, create `.planning/phases/06-hybrid-uat-validators/06-01-SUMMARY.md`
</output>
