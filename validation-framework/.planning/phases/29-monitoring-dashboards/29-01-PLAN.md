---
phase: 29-monitoring-dashboards
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - /media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh
  - /home/sam/.claude/grafana/dashboards/openclaw-overview.json
  - /home/sam/.claude/grafana/alerting/openclaw-alert-rules.yaml
  - /home/sam/.claude/grafana/alerting/openclaw-contact-points.yaml
autonomous: false
---

<objective>
Create Grafana dashboard for OpenClaw monitoring with extended metrics, alerting to Discord/Matrix, and visual verification via OpenClaw Playwright.

Purpose: Complete v7.0 observability — task success rate, token usage, cost trends, quality scores visible at a glance. Alerts on budget exceeded, low success rate, stale metrics.
Output: Dashboard JSON, alert rules, extended metrics in budget-enforcer, visual verification screenshots.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-monitoring-dashboards/29-RESEARCH.md
@.planning/phases/28-usage-tracking/28-01-SUMMARY.md

Existing infrastructure:
- Grafana: http://192.168.1.111:3000 (Workstation)
- Prometheus: http://192.168.1.111:9090 (Workstation)
- node_exporter textfile dir: /media/sam/1TB/moltbot-iac/workstation/node_exporter_textfile/
- Budget enforcer: /media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh (154 LOC)
- Existing metrics: openclaw_daily_cost_usd, openclaw_budget_max_usd, openclaw_budget_exceeded
- OpenClaw gateway logs: ssh 192.168.1.100 "docker exec openclaw-gateway cat /tmp/openclaw/openclaw-YYYY-MM-DD.log"
- Existing dashboard pattern: /home/sam/.claude/grafana/dashboards/ (validation-overview.json)
- Existing alerting pattern: /home/sam/.claude/grafana/alerting/ (alert-rules.yaml, contact-points.yaml)
- Matrix room: !GQeiGgJenxtCKbaxDL:matrix.lan (bambam)
- Discord webhook: ${DISCORD_WEBHOOK_URL} (in .env)
- MCPorter Playwright: npx -y mcporter call playwright.* (on OpenClaw)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend budget-enforcer with additional metrics</name>
  <files>/media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh</files>
  <action>
Extend the Python inline parser in budget-enforcer.sh to extract additional metrics from JSONL logs.

The Python section (starting around line 62) already parses `agentMeta.usage`. Extend it to also track:

1. **Task counts**: Count total lines with `agentMeta`, count those with `result.success === true` vs failures
2. **Token totals**: Sum `usage.inputTokens` and `usage.outputTokens` across all entries
3. **Per-agent breakdown**: Group runs by agent name (from `agentMeta.agent` or session metadata)
4. **Timestamp**: Add `openclaw_last_update_timestamp` with current epoch

After the Python section outputs cost, add additional output variables. Extend the `.prom` file writing section (around line 125) to include:

```
# HELP openclaw_tasks_total Total agent runs today
# TYPE openclaw_tasks_total gauge
openclaw_tasks_total {count}

# HELP openclaw_tasks_success Successful agent runs today
# TYPE openclaw_tasks_success gauge
openclaw_tasks_success {success_count}

# HELP openclaw_task_success_rate Success rate 0-1
# TYPE openclaw_task_success_rate gauge
openclaw_task_success_rate {rate}

# HELP openclaw_tokens_input_total Total input tokens today
# TYPE openclaw_tokens_input_total gauge
openclaw_tokens_input_total {input_tokens}

# HELP openclaw_tokens_output_total Total output tokens today
# TYPE openclaw_tokens_output_total gauge
openclaw_tokens_output_total {output_tokens}

# HELP openclaw_last_update_timestamp Unix timestamp of last update
# TYPE openclaw_last_update_timestamp gauge
openclaw_last_update_timestamp {epoch}
```

Do NOT change the existing cost calculation logic or budget enforcement logic. Only ADD new metric extraction and .prom output.

The Python parser should output a single JSON line to stdout with all metrics (cost + new ones), which bash then parses for both budget logic and .prom writing.
  </action>
  <verify>
Run the script manually: `bash /media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh`
Check .prom file: `cat /media/sam/1TB/moltbot-iac/workstation/node_exporter_textfile/openclaw.prom`
Verify new metrics present: openclaw_tasks_total, openclaw_tasks_success, openclaw_task_success_rate, openclaw_tokens_input_total, openclaw_tokens_output_total, openclaw_last_update_timestamp
  </verify>
  <done>Budget enforcer writes 9+ metrics to .prom file (3 existing + 6 new). Existing budget enforcement unchanged.</done>
</task>

<task type="auto">
  <name>Task 2: Create OpenClaw Grafana dashboard JSON</name>
  <files>/home/sam/.claude/grafana/dashboards/openclaw-overview.json</files>
  <action>
Create a Grafana dashboard JSON file following the pattern from validation-overview.json.

Dashboard structure (4 rows, ~8 panels):

**Row 1: Overview Stats** (4 stat panels, height 4)
- Panel 1: "Daily Cost" — gauge, query `openclaw_daily_cost_usd`, unit: currencyUSD, thresholds: green < 3, yellow < 5, red >= 5
- Panel 2: "Budget Remaining" — gauge, query `(openclaw_budget_max_usd - openclaw_daily_cost_usd) / openclaw_budget_max_usd * 100`, unit: percent
- Panel 3: "Tasks Today" — stat, query `openclaw_tasks_total`
- Panel 4: "Success Rate" — stat, query `openclaw_task_success_rate * 100`, unit: percent, thresholds: red < 70, yellow < 90, green >= 90

**Row 2: Time Series** (2 panels, height 8)
- Panel 5: "Cost Trend" — time series, query `openclaw_daily_cost_usd`, with `openclaw_budget_max_usd` as threshold line (dashed red)
- Panel 6: "Token Usage" — time series, two series: `openclaw_tokens_input_total` (blue), `openclaw_tokens_output_total` (orange)

**Row 3: Task Metrics** (2 panels, height 8)
- Panel 7: "Task Success/Fail" — time series, `openclaw_tasks_success` (green) and `openclaw_tasks_total - openclaw_tasks_success` (red) as stacked
- Panel 8: "Budget Status" — state timeline, `openclaw_budget_exceeded`, 0=OK (green), 1=Exceeded (red)

Dashboard settings:
- uid: "openclaw-overview"
- title: "OpenClaw Overview"
- tags: ["openclaw", "monitoring"]
- refresh: "5m"
- time range: last 24h default
- datasource: Prometheus (use variable `${DS_PROMETHEUS}` or "Prometheus" as default)
- templating: datasource variable for Prometheus

Follow the exact Grafana dashboard JSON schema (dashboard.panels[], with gridPos, fieldConfig, targets, etc.). Use the validation-overview.json as structural reference.
  </action>
  <verify>
Validate JSON: `python3 -c "import json; json.load(open('/home/sam/.claude/grafana/dashboards/openclaw-overview.json'))"`
Check structure: `python3 -c "import json; d=json.load(open('/home/sam/.claude/grafana/dashboards/openclaw-overview.json')); print(f'Panels: {len(d.get(\"panels\",[]))}'); print(f'UID: {d.get(\"uid\",\"\")}'); print(f'Title: {d.get(\"title\",\"\")}')" `
Expected: 8+ panels, uid=openclaw-overview
  </verify>
  <done>Dashboard JSON valid, 8 panels, uid "openclaw-overview", all PromQL queries reference existing metrics</done>
</task>

<task type="auto">
  <name>Task 3: Create alert rules and contact points for OpenClaw</name>
  <files>/home/sam/.claude/grafana/alerting/openclaw-alert-rules.yaml, /home/sam/.claude/grafana/alerting/openclaw-contact-points.yaml</files>
  <action>
Create two YAML files following the pattern from the existing validation alert-rules.yaml and contact-points.yaml.

**openclaw-contact-points.yaml:**
Two contact points:
1. `discord-openclaw-critical` — Discord webhook for budget alerts
   - Type: discord
   - URL: `${DISCORD_WEBHOOK_URL}`
   - Message template with :red_circle:/:green_circle: status, cost info
2. `matrix-openclaw-ops` — Generic webhook for operational alerts
   - Type: webhook
   - URL: placeholder comment explaining to use budget-enforcer's direct Synapse API approach
   - Note: Grafana doesn't have native Matrix support. For Matrix alerts, the budget-enforcer already sends via Synapse API. For Grafana-originated alerts, use a webhook → script that posts to Matrix.

**openclaw-alert-rules.yaml:**
Three alert rules in folder "OpenClaw":

1. `openclaw-budget-exceeded` (Critical)
   - Condition: `openclaw_budget_exceeded == 1`
   - For: 2m
   - Contact: discord-openclaw-critical
   - Annotations: summary, description with cost info

2. `openclaw-low-success-rate` (Warning)
   - Condition: `openclaw_task_success_rate < 0.7` AND `openclaw_tasks_total > 0`
   - For: 10m
   - Contact: discord-openclaw-critical
   - Annotations: summary with current rate

3. `openclaw-stale-metrics` (Warning)
   - Condition: `time() - openclaw_last_update_timestamp > 600` (10 min stale)
   - For: 5m
   - Contact: discord-openclaw-critical
   - Annotations: summary explaining metrics may be stale

Use Grafana provisioning YAML format (apiVersion: 1).
  </action>
  <verify>
Validate YAML: `python3 -c "import yaml; yaml.safe_load(open('/home/sam/.claude/grafana/alerting/openclaw-alert-rules.yaml')); print('OK')"`
Validate YAML: `python3 -c "import yaml; yaml.safe_load(open('/home/sam/.claude/grafana/alerting/openclaw-contact-points.yaml')); print('OK')"`
Check rule count: `python3 -c "import yaml; d=yaml.safe_load(open('/home/sam/.claude/grafana/alerting/openclaw-alert-rules.yaml')); print(f'Groups: {len(d.get(\"groups\",[]))}')"`
  </verify>
  <done>3 alert rules (budget-exceeded, low-success-rate, stale-metrics), 2 contact points (Discord, Matrix placeholder). Valid YAML.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete OpenClaw monitoring stack:
1. Extended budget-enforcer with 6 new Prometheus metrics
2. Grafana dashboard JSON "openclaw-overview" with 8 panels
3. Alert rules for budget, success rate, stale metrics
4. Contact points for Discord alerting

Files created/modified:
- /media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh (extended)
- /home/sam/.claude/grafana/dashboards/openclaw-overview.json (new)
- /home/sam/.claude/grafana/alerting/openclaw-alert-rules.yaml (new)
- /home/sam/.claude/grafana/alerting/openclaw-contact-points.yaml (new)
  </what-built>
  <how-to-verify>
**Option A: Quick verification (manual)**
1. Run budget-enforcer: `bash /media/sam/1TB/moltbot-iac/workstation/budget-enforcer.sh`
2. Check metrics: `cat /media/sam/1TB/moltbot-iac/workstation/node_exporter_textfile/openclaw.prom`
3. Verify 9+ metrics present
4. Import dashboard to Grafana:
   - Visit http://192.168.1.111:3000
   - Dashboards → Import → Upload JSON
   - Select openclaw-overview.json
5. Verify dashboard loads with panels showing data

**Option B: Visual verification via OpenClaw (preferred)**
After importing the dashboard, trigger OpenClaw to take a Playwright screenshot:
```
ssh 192.168.1.100 'docker exec openclaw-gateway node /app/dist/entry.js agent \
  --agent main --message "Use Playwright to navigate to http://192.168.1.111:3000/d/openclaw-overview and take a screenshot. Report what panels you see and whether they show data." --json --timeout 120'
```

**Validation tier checklist:**
- Tier 1 (Blocker): Metrics file written correctly, JSON valid
- Tier 2 (Warning): All 8 panels render, no "No data" panels
- Tier 3 (Monitor): Dashboard loads in < 3s, alert rules parseable
  </how-to-verify>
  <resume-signal>Type "approved" to complete phase, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] budget-enforcer.sh runs without errors
- [ ] .prom file contains 9+ metrics
- [ ] openclaw-overview.json is valid JSON with 8 panels
- [ ] Alert rules YAML valid with 3 rules
- [ ] Contact points YAML valid with 2 entries
- [ ] Dashboard importable to Grafana (visual checkpoint)
</verification>

<success_criteria>

- Budget enforcer extended with task success, token, timestamp metrics
- Dashboard JSON created with 4 rows, 8 panels covering cost, tasks, tokens, budget
- Alert rules configured for budget exceeded, low success rate, stale metrics
- Human verified dashboard renders correctly (manually or via OpenClaw Playwright)
- All files committed to git
  </success_criteria>

<output>
After completion, create `.planning/phases/29-monitoring-dashboards/29-01-SUMMARY.md`
</output>
