---
phase: 12-confidence-loop
plan: 02
type: execute
wave: 1
depends_on: []
files_modified: [validators/behavioral/__init__.py, validators/behavioral/validator.py, validators/behavioral/dom_diff.py, validators/behavioral/tests/__init__.py, validators/behavioral/tests/test_dom_diff.py, validators/behavioral/tests/test_validator.py]
autonomous: true
---

<objective>
Create BehavioralValidator with DOM structure comparison using tree edit distance.

Purpose: Compare DOM structure between expected and actual states to detect semantic changes beyond visual appearance.
Output: Working BehavioralValidator that returns structural similarity confidence.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-confidence-loop/12-RESEARCH.md
@.planning/phases/12-confidence-loop/12-CONTEXT.md
@~/.claude/templates/validation/orchestrator.py
</context>

<quality_requirements>
**MANDATORY for each task:**
1. Write unit tests BEFORE considering task complete
2. Target 95% coverage for new code
3. Run code-simplifier agent if code complexity > 10 or file > 200 LOC
4. Verify each task independently before proceeding to next

**Testing approach:**
- pytest with pytest-cov
- Tests in validators/behavioral/tests/
- Mock external dependencies (zss library, HTML parsing)
- Test edge cases: invalid HTML, missing zss, malformed DOM
</quality_requirements>

<tasks>

<task type="auto">
  <name>Task 1: Create dom_diff.py with tree edit distance + tests</name>
  <files>~/.claude/templates/validation/validators/behavioral/dom_diff.py, ~/.claude/templates/validation/validators/behavioral/tests/__init__.py, ~/.claude/templates/validation/validators/behavioral/tests/test_dom_diff.py</files>
  <action>
Create DOM tree comparison using Zhang-Shasha algorithm:
- DOMComparator class
- parse_html(html: str) -> tree structure suitable for comparison
- compare(baseline_html: str, current_html: str) -> dict
- Return: edit_distance, similarity_score (0-1), operations (insertions, deletions, renames)

Implementation:
- Use zss (Zhang-Shasha) library for tree edit distance
- Parse HTML with html.parser or lxml, convert to zss Node format
- Filter to meaningful elements (exclude script, style, meta, comments)
- Normalize whitespace and attributes
- similarity_score = 1.0 - (edit_distance / max(tree1_size, tree2_size))

Graceful degradation if zss not installed.

**THEN write tests in test_dom_diff.py:**
- test_compare_identical_html: similarity_score = 1.0
- test_compare_different_html: similarity_score < 1.0, operations listed
- test_zss_not_installed: graceful degradation when library missing
- test_invalid_html: handle malformed HTML gracefully
- test_filter_elements: script/style/meta excluded
- test_whitespace_normalization: whitespace differences ignored
- test_empty_html: handle empty input

**VERIFY:**
```bash
cd ~/.claude/templates/validation
pytest validators/behavioral/tests/test_dom_diff.py -v --cov=validators/behavioral/dom_diff --cov-report=term-missing
```
Coverage must be >= 95%.

**CODE QUALITY:** If file > 200 LOC or complexity high, run code-simplifier.
  </action>
  <verify>pytest validators/behavioral/tests/test_dom_diff.py -v --cov=validators/behavioral/dom_diff --cov-fail-under=95</verify>
  <done>DOMComparator works, tests pass with 95%+ coverage</done>
</task>

<task type="auto">
  <name>Task 2: Create BehavioralValidator with structural scoring + tests</name>
  <files>~/.claude/templates/validation/validators/behavioral/validator.py, ~/.claude/templates/validation/validators/behavioral/__init__.py, ~/.claude/templates/validation/validators/behavioral/tests/test_validator.py</files>
  <action>
Create BehavioralValidator that checks DOM structural similarity:
- Extends BaseValidator pattern from orchestrator
- dimension = "behavioral", tier = ValidationTier.MONITOR (Tier 3)
- validate(baseline_html: str, current_html: str) -> ValidationResult
- Confidence = similarity_score from DOMComparator
- Store operations list in details for debugging

Config options:
- similarity_threshold: 0.90 (default for "match")
- ignore_attributes: ["id", "class", "style"] (optional)
- focus_selectors: ["main", "article", ".content"] (optional - compare subset)

Create __init__.py exporting BehavioralValidator.

**THEN write tests in test_validator.py:**
- test_validate_identical_dom: confidence = 1.0 when HTML matches
- test_validate_different_dom: confidence < 1.0 when HTML differs
- test_config_similarity_threshold: respects threshold setting
- test_ignore_attributes: specified attributes ignored
- test_focus_selectors: only compares selected elements
- test_returns_validation_result: correct ValidationResult structure
- test_operations_in_details: edit operations stored

**VERIFY:**
```bash
cd ~/.claude/templates/validation
pytest validators/behavioral/tests/test_validator.py -v --cov=validators/behavioral/validator --cov-report=term-missing
```
Coverage must be >= 95%.

**CODE QUALITY:** If file > 200 LOC or complexity high, run code-simplifier.
  </action>
  <verify>pytest validators/behavioral/tests/test_validator.py -v --cov=validators/behavioral/validator --cov-fail-under=95</verify>
  <done>BehavioralValidator works, tests pass with 95%+ coverage</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Both modules importable without errors
- [ ] DOMComparator handles missing zss library gracefully
- [ ] BehavioralValidator returns confidence score 0-1
- [ ] Tree edit distance calculation produces reasonable results
- [ ] Whitespace and attribute normalization works
</verification>

<success_criteria>

- All tasks completed
- BehavioralValidator follows BaseValidator pattern
- DOM similarity score correctly computed
- Graceful degradation when zss unavailable
</success_criteria>

<output>
After completion, create `.planning/phases/12-confidence-loop/12-02-SUMMARY.md`
</output>
